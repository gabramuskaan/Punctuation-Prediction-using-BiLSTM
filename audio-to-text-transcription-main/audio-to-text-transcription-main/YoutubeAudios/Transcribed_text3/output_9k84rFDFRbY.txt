 So, this lecture is on algorithms for sorting and the focus of the lecture is going to be not just on the algorithms, but the sequence of steps that going to arguing that the algorithm is indeed correct in analyzing the running time. One of the simplest algorithms to sort a given data set and in this case we assume that the input is given in an array of size n that the elements are a of 1 to a of n. The data type of the elements in the array is not so important for the rest of the presentation as long as it is clear that there is a very clear order between every pair of elements. The output of a sorting algorithm is to sort the array in ascending order and insertion sort is a very simple and popular algorithm to understand the challenge of sorting. The approach that is taken by insertion sort is the following, it is an iterative approach which means that there is a loop that is running n times recall that n is a number of elements in the array that need to be sorted and at the end of every iteration let us say at the end of the ith iteration the invariant that is maintained by the algorithm is that the elements from the first I elements in the array that is the elements a of 1 to a of i are sorted in ascending order. Further in the ith iteration the element a of i is inserted into the correct location among the elements a of 1 to a of i minus 1 and thus this invariant is maintained one iteration after another this kind of guarantees the correctness of the insertions and sort algorithm to sort an array of n elements. Of course, the challenge here is to understand how the insertion happens recall that in the previous slide we mentioned that in the ith iteration the element a of i is inserted into the correct location so that a of 1 to a of i is sorted given that a of 1 to a of i minus 1 is sorted when the control enters the ith iteration. So, how does one insert a of i? One can look at the step by step procedure we said first j to be a temporary variable and then if j whenever j takes the value 1 you exit right we will see what the motivation for this condition is and as long as j is more than 1 a comparison is made of the elements a of j and a of j minus 1 in other words the elements which are in the array locations j and j minus 1 are compared and if a of j is smaller than a of j minus 1 then there is an exchange that is affected between the elements in the locations j and j minus 1 and now j is decremented by 1 and then we repeat this procedure all over again. Indeed it is also possible that the element at the jth location is at least as large as the element at the j minus 1 with location in which case it is clear that a of j is at the correct place given that the rest of the elements are in sorted order right at this point of time the control exits and now we can report that the elements a of 1 to a of i are in sorted order in other words we achieve the goal of inserting a of i into the correct position. Let us just look at this pictorially this is taken from Korman-Lyser's and Rivas the standard textbook and let us look at the starting array which is array index by the letter a and observe that there are six elements in this array which are which start out as 5, 2, 4, 6, 1 and 3 observe that in the first step right in our case this would be the second step the way I presented the algorithm the elements 2 and 5 are exchanged in the array index by the letter b observe that the first two elements are in sorted order and the element 4 is now being inserted into its correct position and this just requires a single comparison with 4 and 5 but of course the comparison with two should also happen therefore it actually requires two comparisons similarly if you look at six six is larger than 5 and this one comparison keep six exactly where it is and then observe that 1 is now inserted into the correct position after 4 exchanges 6 first goes into the is exchanged with 1 then 5 with 1 then the value 4 with 1 and finally the value 2 is exchanged with 1. Similarly 3 now is move towards is inserted into its correct place in the figure index by the letter e at the end of this whole procedure we find that the array is in sorted order this is essentially the idea behind the insertion sort and one can even imagine this as a very natural way of arranging a deck of cards how does one guarantee the correctness of this insertion sort algorithm the way to guarantee the sortness to guarantee the correctness of this sorting algorithm is to now argue that in the I th iteration the element a of i will move to its correct position among the elements a of 1 to a of i minus 1 within i comparisons in other words we prove this by induction we observe that at the end of the I th iteration the elements a of 1 to a of i minus 1 are sorted in a of i are sorted in ascending order we prove this by induction on the value of i observe that when i is equal to 1 which is the base case the array just contain a of 1 is just in sorted order. So let us assume that a of 1 to a of i minus 1 are sorted in ascending order and let us complete the induction step so the hypothesis now is the a of 1 to a of i minus 1 are sorted in ascending order. Now a of i let us assume the a of i is now inserted between the elements a of j and a of j plus 1. So let us look at the indices that j can take j can take a value between 1 and i minus 2 and wherever it is inserted on termination it is clear that a of i is at least as large as a of j and a of i is less than or equal to a of j plus 1. In other words as the algorithm progresses the prefix of the array which is sorted its length keeps increasing iteration by iteration. Consequently at the end of the n th iteration it is clear that the elements a of 1 to a of n occur in sorted order therefore insertion sort is indeed correct in the sense that it terminates an on termination the array is in sorted order. The analysis of the running time is based on the observation that for the element a of i to be inserted into its correct location in the worst case it just need 2 times i minus 1 comparisons we use comparisons as a measure of the running time and we count the total number of comparisons that need to be made to ensure that i is inserted into the correct place and here we place an upper bound in other words we do a worst case analysis of the number of comparisons which are required. And observe that if the element the worst case is the case where the element a of i should eventually enter the location a of 1 in other words in the elements a of 1 to a of i a of i turns out to be the smallest element in this sub array of consecutive elements then a of i indeed has to be compared with each of the elements that is i minus 1 all the way up to the element index at i minus 1 up to the element index by y by 1. Further in each of these iterations if you notice the code that we have written there is a comparison of whether the index is equal to 1 or not right. So, that is why we get 2 into i minus 1 comparisons therefore, the total number of comparisons made is 1 comparison for the first element and subsequently it is an even number of comparisons up to the the nth element right therefore, the total number of comparisons that is made is given by the summation 1 plus 2 plus 4 plus 6 and so on up to 2 times n minus 1. Here is a small exercise which is indeed a toy exercise calculate is exactly and verify that it is of the order of n square. So, this brings to end the discussion of insertion sort and it is instructive to see on what input insertion sort performs the most number of comparisons. This is also left as a small exercise to the student. Natural question now is that can we reduce the number of comparisons made by a sorting algorithm from order of n square to something significantly smaller than n square right. We now show an algorithm which uses the divided conquer paradigm recall that in the last lecture where we studied binary search we encountered the divided conquer paradigm where in that case we were searching for a particular element in a sorted array and in every iteration the region of the array which is sorted became smaller by a fraction of 2. In this case we do something similar we create two sub problems of almost equal size sort the two sub problems recursively and then merge the sorted arrays. So, this is the whole idea this is the divided conquer paradigm and this is what merge sort does right. The sequence of steps are as follows for the goal of sorting an array whose indices are in the interval p to q where p is smaller than q. Initially the first time when merge sort would be called the value of p would be 1 and q would be n that is we would we want to sort the array of size n. The algorithm takes a middle element in the given array in this case it computes the index given by the formula R which is the floor of p plus q by 2. In other words the range p plus q is taken which is the sum of the two elements divided by 2 gives the middle index in the array and we take the floor just in case p plus q is odd. If R is not same as p in other words if the array has more than one element or more than three elements if the array has more than three elements then merge sort of p comma R is called followed by a recursive call to merge sort of R plus 1 to q. Observe here is a boundary condition of what happens when R is equal to p. Observe that when R is equal to p there are at most two elements in the array and there is no need to recursively sort the elements of size 1. Now the two arrays a of p to R and a of R plus 1 to q are now sorted recursively using merge sort itself at the end of which the array a of p comma R and a of R plus 1 comma q are sorted arrays. We call a function called merge which we will shortly discuss the output of merge is to take these two sorted arrays and insert them into a third array which is called b here. b contains all the elements of both the arrays in sorted in ascending order. Now b is now copied into the array p comma q which is now sorted and this is the description of the recursive algorithm. The natural question now is how many comparisons are made by this merge sort algorithm. Before we go there let us look at a key step which plays an important role in the merge sort algorithm which is the time taken to merge two sorted arrays. Let us look at it as an independent exercise not just in the context of merge sort but just the question of the input consisting of two sorted arrays and the output should be a third array which contains all the elements of the two arrays in sorted order. This operation is called the merging operation of the two sorted arrays a and b. So let us look at the time taken to merge the two arrays a and b into a sorted array c. The idea is quite intuitive. So initially x and y are taken to be one they are the smallest elements in the two arrays respectively and z is the first element the index of the first element in the array c. The first step is the following which is very important this is the beginning of an iteration if z exceeds the total number of elements in the array in the two arrays then you exit merge has been completed you return the value of c the algorithm returns the value c. In the second step the smallest of the two elements second in the second step the smallest of the two elements a of x and b of y are identified and the smallest of the two elements is now assigned to be the element present in the array index z in the array c. This is iteratively done as follows a of x is compared with b of y the smaller the two elements as you can see is assigned to c of z. z is then incremented and depending on where the smaller element came from whether it came from a or b the indices x and y are incremented the indices y and x are incremented. For example if the smaller element came from the array y array b then the element assigned to c of z is b of y and y is now incremented and z is also incremented. If the smaller element came from the array a then x and z are incremented and the array element a of x is copied into the array index z in c. Now we will argue that this indeed merges the two arrays and we will also count the total number of comparisons made. At this point of time before we go into that argument let us just look at the execution of the merge out algorithm and again this image is taken from the textbook by Convent License and Drive-Aest and let us look at the run of this algorithm. The leaf levels in this tree tell us the initial array the initial array has had eight elements and the elements are 5, 2, 4, 7, 1, 3, 2 and 6 and observe that in this view every intermediate array that you see as you view this in a bottom of fashion is a sorted array and the parent of two arrays is obtained by merging the contents of the two sorted arrays. Let us just look at the leaf level let us look at the elements 5 and 2 individually sorted order and they are merged to result in the parent array which has the elements 2 and 5. If you look at the sibling the right sibling of the array 2, 5 it is 4, 7 which is obtained by merging the two arrays which have just a single element 4 and 7 respectively. Now 2, 5 and 4, 7 as you can see is merged to give the array 2, 4, 5 and 7 and eventually the whole sorted sequence is obtained at the root of this recursion tree. It is important to observe that this data structure is present only in the analysis of the algorithm and the algorithm indeed does not run in this order. It runs in a top down order as opposed to the analysis which is happening or which is being presented in a bottom up fashion. Let us look at the correctness analysis of the merging step. The merging step is indeed correct. So let us just observe a primary invariant which says that for every z in the range 1 to L plus m after the z z iteration, C of z satisfy some nice properties. C of Z is smaller than all the values in the array A among the region x to L, among the indices x to L and it is smaller than all the values in the array B among the indices y to m. Therefore, it follows that C of 1 to Z. All the values are at most each value in the array indices x to L in A and the array indices y to m in the array B. The third property that is guaranteed by the algorithm is that the array C is sorted for every z. So remember that z is the iteration number. To prove the above claim, it is sufficient. If we prove the above claim, this proves that the merge algorithm is indeed correct because when you take the value z is equal to L plus m, the array C of 1 to Z would be sorted. That is the whole array is sorted because of the range of values that z takes from 1 to L plus m. Continuing the correctness analysis, we set up the proof by induction. Let us assume that z is equal to 1 and in this case, the singleton array, the array containing just one element is sorted. It is indeed the smallest element in the array is A and B. Therefore, our claim is correct in this base case. Let us assume and let us make the induction hypothesis that the claim is indeed true for a value z minus 1. Let us prove this for z. This would complete the induction step. So, the first claim is that C of z is the smallest element in A of x and among A of x and B of y. This is indeed correct. Because if you look at the steps in the algorithm, we choose the minimum of the elements A of x and B of y and assign it into the value C of z. Therefore, C of z is indeed the minimum. Since A and B are sorted, it is clear that C of z is indeed smaller than the elements in the array locations x to L in the array A and the elements in the array locations y to m in the array B. By induction, we know that C of z minus 1 is indeed smaller than or equal to C of z. In other words, we know that by induction that C of z minus 1 is smaller than equal to all the elements in the arrays A and B put together and we have taken the minimum of all those elements and put them into C of z. Therefore, C of z minus 1 is smaller than or equal to C of z. Consequently, it follows that C of 1 to z is in the sorted order given that C of 1 to z minus 1 was in the sorted order by the induction hypothesis. This proves the induction step and therefore, we have proved that merge indeed does succeed that after L plus m iterations, the whole array C is in the sorted order and therefore, the merge algorithm indeed succeeds. Let us now analyze the running time of merge. It is very important to get an understanding of how much time it takes for merge to run. It is crucial to understand how does one count the running time and in this case, we count the total number of comparisons. The most important observation that we make is that every time a comparison is affected, the size of the array C keeps increasing by exactly 1. As a consequence of this observation, after L plus m comparisons, there will be L plus m elements in the arrays C and therefore, the total number of comparisons used is a sum total of the total number of arrays elements in the two arrays A and B. Therefore, the number of comparisons used by the merge algorithm is L plus m. In other words, it is just linear in the size of the number of elements in the two arrays put together. This gives a handle to analyze the running time of merge sort. Again, here we count the total number of comparisons made by merge sort. Let us now analyze the number of comparisons used by the merge algorithm. Let T of n denote the number of comparisons made by merge sort on an n element array. For the sake of simplicity, just for the argument, let us assume that n is the power of some value k, that is n is equal to 2 power k. Now, T of n is given by the formula, T of n is 2 times T of n by 2 plus m and T of 2 is just equal to 1. Let us just understand this formula. This is called a recurrence equation and 2 times T of n by 2 is equal to 1 plus the number of comparisons on the recursive subproblems to sort the recursive subproblems. That is the subproblem consisting of 1 half of the array and the second subproblem consisting of the second half of the array. The second term which is n is the total number of comparisons made by merge, which we just very recently analyzed. A solution to this recurrence equation gives us a solution to the number of comparisons made by the merge sort algorithm and this will be completed in the next lecture.