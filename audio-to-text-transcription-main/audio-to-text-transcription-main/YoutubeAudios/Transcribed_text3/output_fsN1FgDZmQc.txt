 Today, we are going to study a second problem which is solved using the method of dynamic programming. This problem is called the matrix chain multiplication. The problem is that we are given a sequence of matrices that can be multiplied. So, A1, A2 up to A n are n matrices which are given and our aim is to compute the product of these n matrices. Let us assume that the product can be performed. In other words, the orders of the matrices are appropriately given. There are many parenthesisizations to compute the product. What is a parenthesisization? The parenthesisization is an allocation of parenthesis around the expression that has been given so that the expression can be evaluated as specified by the parenthesisization. Let us now consider this example where there are four matrices A1, A2, A3 and A4 and A is to compute the product of these four matrices. There are five possible parenthesisizations. Let us inspect each of these parenthesisizations. This is the first one. We know that in any expression which is parenthesized, the innermost parenthesis is evaluated first. Therefore, in this parenthesisization, the first one, A3 and A4 are multiplied first. The result is then multiplied with A2 and the result is then multiplied with A1. In the next parenthesisization, the innermost parenthesis is the one that encloses the product A2, A3 which is computed first. The result is then multiplied with A4. The result of this matrix multiplication is then multiplied with A1. The other parenthesis, this is more interesting than the first two because it is different. Observe that there are two innermost parenthesis. One parenthesis contains the matrix product A1, A2 and the second innermost parenthesis contains the matrix product A3, A4 and again using expression evaluation rules, the innermost parenthesis is evaluated first. Therefore, the expression involving the product A1, A2 is evaluated first. Then the expression involving the product A3, A4 is evaluated. Then the two results are multiplied and this is given as a result of the matrix product of the four matrices. The following two are symmetric to the second and first respectively and the explanation is similar. What distinguishes these five different parenthesisizations? Let us just see that. What distinguishes them is the total number of multiplications. Our aim is to now count the total number of scalar multiplications which are necessary. To do this, let us understand the number of multiplications required to multiply two matrices. In this case, let us assume that the matrix dimensions are given. The two matrices are A, which is a P by Q matrix and B, which is a Q by R matrix. We know that the result is a P by R matrix and let us call this result matrix, the value, the matrix C. It is clear that the total number of matrix multiplications that need to be performed is PQR. It is clear that the total number of matrix multiplications that need to be performed is P multiplied by Q multiplied by R. How does this affect the behavior of chain matrix multiplication? For this, let us consider the following example where we consider three matrices, A, B and C, A is a order 10 by 100, B is a order 100 by 5 and C is a order 5 by 50. Clearly, the three matrices can be multiplied, that is, the product A, B, C can be computed. There are two ways of parenthesizing this. This is the first way where the product A, B is computed first. The result is multiplied with C. Let us assume that the product A, B is called D. We know that it is a 10 by 5 matrix and C is a 5 by 50 matrix. The multiplication A, B takes 5,000 scalar multiplications. The product D, C takes 2500 scalar multiplications. Therefore, the total number of scalar multiplications is 7500. Let us consider the second parenthesization where B and C are multiplied first followed by A. Let the outcome of multiplying B and C, B, the matrix E, which is a 100 by 50 matrix. So, the product B multiplied by C, which is performed first, takes 25,000 scalar multiplications. The subsequent product of A and E takes 50,000 scalar multiplications. And therefore, we can already see that the first parenthesization uses only 7500 scalar multiplications, but the second parenthesization uses 10 times more number of scalar multiplications. That is, it uses 75,000 scalar multiplications. Clearly, from an efficiency point of view, the first parenthesization is a more preferred parenthesization than the second parenthesization. This gives rise to a very interesting minimization problem. This minimization problem is called the matrix chain multiplication problem. The input to the matrix chain multiplication problem is a chain of n matrices A1, A2 to A n. For every i, the i-th matrix has dimension P i minus 1 cross P i. That is, the matrix A i has P i minus 1 rows and P i columns. The first matrix A 1 has P 0 rows and P 1 columns. The goal is to parenthesis this matrix. The goal is to parenthesis this chain A1, A2 to A n so that the total number of scalar multiplications is minimized. Recall from the previous example that different parenthesizations give rise to different number of scalar multiplications. And our aim is to choose the optimal optimal parenthesization to minimize the total number of scalar multiplications. One natural approach is the brute force method where we try all possible parenthesizations. I leave this as an exercise to the student to calculate how many parenthesizations are there for a chain of n matrices. It is indeed an exponential in n. The exact function is left as an exercise to the student. So now let us use the dynamic programming approach to come up with an algorithm to find the minimum parenthesization. Let us use the dynamic programming approach to come up with an algorithm which will come up with a parenthesization that uses the minimum number of scalar multiplications. To do this let us understand the structure of an optimal solution which in this case is a parenthesization. For this we need some simple notation. We use the notation A subscripted by i up to j to denote the matrix which is a result of the product A i A plus 1 and so on up to A j. Let us know observe that in an optimal parenthesization which we do not know which is what our algorithm is trying to compute in an optimal parenthesization. Let k be the index where the product A1 A2 to A n is split. Therefore the approach for computing the product would first be to compute the matrices A1 k and A k plus 1 n and then compute the product of these two matrices to get the final matrix A1 n. The k observation that we make about this whole exercise is that if we consider an optimal parenthesization of the chain A1 A2 to A n then the parenthesizations of the subchains A1 A2 to A k and A k plus 1 A k plus 2 to A n will also be optimal. This is the optimal substructure. Recall that from the previous lecture this is one of the properties of recall from the previous lecture for dynamic programming to be used the problem must have the optimal substructure. In other words in this case the optimal solution to the parenthesization contains within it the optimal solution to subproblems. So we will verify the claim that this problem has optimal substructure while coming up with a recursive formulation of the optimum values. In this case we again introduce a few variables which are necessary for us to compute the minimum number of scalar multiplications. So we use the two-dimensional array m i comma j to denote the minimum number of scalar multiplications necessary to compute A i j. We let m i comma j denote let m i comma j by B let m i comma j be the minimum number of scalar multiplications necessary to compute A i j. Now we can see that the minimum cost to compute the chain product A1 to A n recall this is A subscripted by the range 1 to n is the value m of 1 comma n. Suppose the optimal parenthesization of A i j splits the product between A k and A k plus 1 where k is a number in the range i to j. Then we write down a recursive formulation of m of i comma j. So recursive formulation uses this parenthesization. The matrix A i j is obtained by the parenthesization. The matrix A i j is obtained by multiplying the matrix chain A i to A k with the result of the matrix chain A k plus 1 to A j. In other words this is the product of the two matrices A i k multiplied by A k plus 1 j. Therefore the total cost of computing A i j is the cost of computing A i k plus the cost of computing A k plus 1 j plus the cost of multiplying the two matrices A i k and A k plus 1 j. Note here that the cost is the total number of scalar multiplications. So we know that the third term the cost of multiplying A i k and A k plus 1 j is P i minus 1 multiplied by P k multiplied by P j. This is because the order of the two matrices are P i minus 1 cross P k and P k cross P j. So we specify the recurrence now completely which is that the minimum number of scalar multiplications for the chain, the minimum number of scalar multiplications for multiplying the chain A i to A j is equal to M of i k plus M of k plus 1 k plus 1 k plus P i minus 1 multiplied by P k multiplied by P j for k between i and j. And indeed the number of multiplications to compute an empty product is 0 that is M of i k i is the cost of multiplying A i where there are no multiplication operations involved therefore this is taken to be the values 0. To complete the recursive formulation let us observe that the optimal parenthesisization occurs at one of the values of k between i and j. We do not know which one it is but the algorithmic idea is very simple we check all the possible values of k between the range i and j and select the one that gives the least value and this specifies completely the recursive formulation of M of i k i j. If i and j are the same it is 0 because we do not have to perform any multiplication if i not equal to j and i is strictly smaller than j then M of i k i j we know stores the minimum number of scalar multiplications to multiply the chain product A i to A j. So this is obtained by finding the best value of k by computing M of i k i plus M of k plus 1 k j plus P minus 1 multiplied by P k multiplied by P j and choosing the best possible k that gives the minimum value of M of i k i j. This completes the recursive formulation of the minimum that we are interested in. Now we need to convert this recursive formulation into an algorithm and we have to specify the algorithm and efficient algorithm to compute the minimum. To do this we introduce a second two-dimensional array which we call s, s stands for split and we refer to this two-dimensional array as the split table. The split table tells us where to split a chain. In other words s of i comma j is that value of k at which the chain A i to A j is split for an optimal parenthesization. The steps in this algorithm are to compute the minimum number of scalar multiplications for chains of length 1. From there we compute the minimum number of parenthesizations for chains of length 2 and 3 and so on. This is the bottom-up calculation method of the optimum value of M of 1 comma M. This is the algorithm description. There is an initialization phase where the mincos table M is initialized with 0 for all the diagonal entries because they do not involve any multiplication. This is followed by three nested iterations to essentially implement the recurrence and the outer loop iterates over. So let us consider this algorithmic description to compute the optimal cost. We will then compute the optimal parenthesization also. The input to this algorithm is an array which is an n plus 1 element array which contains the dimensions of the matrices. For example, the fields P of 0 and P of 1 give us the information about the dimension of matrix A 1 that is P0 cross P1. The array entries P1 and P2 tell us the dimension of the matrix A 2 and so on. The result of this algorithm is we get a mincos table and a split table. These are two arrays that we get. The mincos table stores the value of the minimum cost parenthesization of the chain multiplication involving the chains involving the chain of matrices A i A i plus 1 up to A j. Similarly, the split table the entry S of i j stores the value of the index k at which the chain A i to A j is to be split. The algorithm is as follows. It has four four loops. The first four loop is an initialization phase where the diagonal entries are all initialized to 0. This is natural because the diagonal entries store the value 0 to denote the fact that there is no matrix multiplication involving a single matrix. The remaining three four loops are nested and the intent of these four loops is to fill the remaining entries in the upper half of the matrix is to fill the entries in the upper half of the matrix and this is done by filling each diagonal. Observe that there are n minus 1 diagonals apart from the principal diagonal of the matrices. The outer loop iterates over the diagonals of the matrix. The outer four loop which is indexed by the variable L iterates over the diagonals. The next four loop is set up to instantiate each element in the appropriate diagonal and the innermost four loop is the one that evaluates the value of the min cos parenthesis. So, in the second four loop the initialization of the variable j to i plus L minus 1 is a choice of the appropriate element in the L th diagonal. So, m of i comma j is initialized to the value empty which is a standard thing for a minimization problem which takes positive values. m of i comma j is initialized to the value infinity which is a standard practice for minimization problems which take positive values. The innermost four loop is the loop that implements the recurrence that we have written to formulate the value of m of i comma j. The way this is done is to iterate over all the possible values of k starting from i to j minus 1 and the value q is computed as m of i comma k plus m of k plus 1 comma j plus p of i minus 1 multiplied by p of k multiplied by p of j. The if statement updates the value of m of i comma j if the value of q is smaller and it also updates the value of the split entry if the value of q is smaller than the current value of m of i comma j. At the end of this whole iteration the matrices m and s are computed and they store the optimum parenthesis for every i comma j they store the optimum number of scalar multiplications for the chain multiplication involving a i to a j and the parenthesis information is stored by keeping track of the split value in the matrix s. The split table is used to compute an optimum solution the algorithm computes first the min cost table m and the split table s as we saw in the previous slide and the optimum solution can be calculated from the split table using the value k which is stored in s of i comma j this enables us to compute s of 1 comma n recursively. Thank you.